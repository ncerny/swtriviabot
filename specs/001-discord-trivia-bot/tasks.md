# Task Breakdown: Discord Trivia Bot

**Feature**: 001-discord-trivia-bot  
**Branch**: `001-discord-trivia-bot`  
**Date**: 2025-10-25  
**Total Tasks**: 43

## Summary

This task breakdown organizes implementation by user story priority, enabling independent development and testing of each feature increment. Each user story phase is a complete, deployable MVP slice.

**User Stories**:

- **US1 (P1)**: Submit Trivia Answer - Core answer submission with duplicate detection
- **US2 (P2)**: View All Answers - Admin command to list all submissions
- **US3 (P3)**: Reset Trivia Session - Admin command to clear answers

**Task Distribution**:

- Phase 1 (Setup): 8 tasks
- Phase 2 (Foundational): 6 tasks
- Phase 3 (US1 - P1): 9 tasks
- Phase 4 (US2 - P2): 6 tasks
- Phase 5 (US3 - P3): 6 tasks
- Phase 6 (Polish): 8 tasks

**MVP Recommendation**: Complete through Phase 3 (US1) for a functional answer submission bot.

---

## Implementation Strategy

### MVP-First Approach

1. **First Release (US1)**: Users can submit and update answers

   - Delivers immediate value: answer collection works
   - Testable: User submits, sees confirmation, updates answer
   - No admin features needed for initial testing

2. **Second Release (+US2)**: Add answer viewing for admins

   - Enables trivia host to review submissions
   - Independent of US1 (doesn't change answer logic)
   - Testable: Admin lists answers after US1 submissions

3. **Third Release (+US3)**: Add session reset
   - Convenience feature for multiple rounds
   - Independent of US1 & US2
   - Testable: Reset clears, new answers accepted

### Parallel Execution Opportunities

Tasks marked [P] can be executed in parallel with other [P] tasks when they:

- Operate on different files
- Have no dependencies on incomplete tasks
- Don't share state or resources

**Phase 3 (US1) Parallelization**:

- T015 [P] [US1] + T016 [P] [US1] (different files: answer.py vs session.py)
- T017 [P] [US1] + T018 [P] [US1] (different files: answer_service.py vs storage_service.py)

**Phase 4 (US2) Parallelization**:

- T025 [P] [US2] + T026 [P] [US2] (different files: list_answers.py vs formatters.py)

**Phase 5 (US3) Parallelization**:

- T031 [P] [US3] + T032 [P] [US3] (different files: reset_answers.py vs answer_service.py updates)

---

## Dependencies

### Story Completion Order

```text
Phase 1 (Setup)
    ‚Üì
Phase 2 (Foundational)
    ‚Üì
Phase 3 (US1 - P1) ‚Üê MUST complete before US2 or US3
    ‚îú‚îÄ‚Üí Phase 4 (US2 - P2) ‚Üê Can start after US1
    ‚îî‚îÄ‚Üí Phase 5 (US3 - P3) ‚Üê Can start after US1
         ‚Üì
Phase 6 (Polish)
```

**Critical Path**: Setup ‚Üí Foundational ‚Üí US1 ‚Üí US2 ‚Üí US3 ‚Üí Polish

**Independent Branches**: US2 and US3 can be developed in parallel after US1 completes.

---

## Phase 1: Setup (Project Initialization)

**Objective**: Initialize project structure and development environment

**Tasks**:

- [x] T001 Create project directory structure per plan.md (src/, tests/, data/, config/, perf/)
- [x] T002 Create requirements.txt with discord.py>=2.3.0, python-dotenv>=1.0.0, pytest>=7.4.0, pytest-asyncio>=0.21.0, pytest-cov>=4.1.0
- [x] T003 [P] Create .env.example file with DISCORD_BOT_TOKEN placeholder
- [x] T004 [P] Create .gitignore with .env, data/, **pycache**/, \*.pyc, .pytest_cache/, .coverage, htmlcov/
- [x] T005 [P] Create Procfile with "bot: python src/bot.py"
- [x] T006 [P] Create README.md with project overview, setup instructions, and Discord bot registration steps
- [x] T007 [P] Configure pytest in pyproject.toml or pytest.ini (async mode, coverage settings)
- [x] T008 [P] Configure flake8, black, and mypy configuration files for code quality

**Validation**: Project structure matches plan.md, all config files present, `pip install -r requirements.txt` succeeds

---

## Phase 2: Foundational (Blocking Prerequisites)

**Objective**: Implement core infrastructure needed by all user stories

**Tasks**:

- [x] T009 Create src/models/**init**.py with exports for Answer and TriviaSession
- [x] T010 Create src/services/**init**.py with exports for services
- [x] T011 Create src/commands/**init**.py for command handlers
- [x] T012 Create src/utils/**init**.py for utility functions
- [x] T013 Implement src/utils/validators.py with validate_answer_text(text: str) ‚Üí str function
- [x] T014 Implement src/utils/formatters.py with format_answer_list(answers: list[Answer]) ‚Üí str function

**Validation**: All **init**.py files present, validators and formatters have docstrings and type hints

---

## Phase 3: User Story 1 - Submit Trivia Answer (P1)

**Story Goal**: Users can submit answers via `/answer` command and receive confirmation. Duplicate submissions show update message and replace previous answer.

**Independent Test Criteria**:

- User runs `/answer Paris` ‚Üí sees "‚úÖ Your answer has been recorded!"
- Same user runs `/answer France` ‚Üí sees "üîÑ You've already answered this question - updating your answer!"
- Answer is stored with user_id, username, text, timestamp
- Subsequent `/answer` replaces previous answer (only one answer per user)

**Tasks**:

- [x] T015 [P] [US1] Create src/models/answer.py with Answer dataclass (user_id, username, text, timestamp, is_updated attributes)
- [x] T016 [P] [US1] Create src/models/session.py with TriviaSession class (guild_id, answers dict, created_at, last_activity attributes)
- [x] T017 [P] [US1] Implement src/services/answer_service.py with submit_answer(guild_id, user_id, username, text) ‚Üí tuple[Answer, bool] function
- [x] T018 [P] [US1] Implement src/services/storage_service.py with load_session_from_disk(guild_id), save_session_to_disk(guild_id, session), functions
- [x] T019 [US1] Create src/bot.py with Discord client initialization, intents configuration, and command tree setup
- [x] T020 [US1] Implement session loading in src/bot.py startup (load all /data/\*.json files into memory)
- [x] T021 [US1] Implement src/commands/answer.py with /answer slash command handler
- [x] T022 [US1] Integrate answer_service and storage_service in answer command handler
- [x] T023 [US1] Add error handling in answer command for empty input and validation failures

**Integration Test**:

1. Start bot
2. User A runs `/answer Paris` ‚Üí sees success message
3. Verify /data/{guild_id}.json created with User A's answer
4. User A runs `/answer France` ‚Üí sees update message
5. Verify /data/{guild_id}.json updated with new answer
6. User B runs `/answer London` ‚Üí sees success message
7. Verify /data/{guild_id}.json contains both answers

---

## Phase 4: User Story 2 - View All Answers (P2)

**Story Goal**: Admins can view all submitted answers with usernames via `/list-answers` command. Non-admins see permission error.

**Independent Test Criteria** (requires US1 complete):

- Multiple users submit answers using `/answer` (from US1)
- Admin runs `/list-answers` ‚Üí sees formatted list with all usernames and answers
- Non-admin runs `/list-answers` ‚Üí sees "‚ùå You don't have permission to use this command"
- When no answers exist ‚Üí sees "üìã No answers submitted yet"

**Tasks**:

- [x] T024 [US2] Create src/services/permission_service.py with check_admin_permission(interaction) ‚Üí bool function
- [x] T025 [P] [US2] Implement src/commands/list_answers.py with /list-answers slash command handler
- [x] T026 [P] [US2] Update src/utils/formatters.py to handle empty answer lists and format with emoji header
- [x] T027 [US2] Add permission decorator to /list-answers command using @app_commands.checks.has_permissions(administrator=True)
- [x] T028 [US2] Integrate permission_service and formatters in list_answers command handler
- [x] T029 [US2] Add error handling for permission errors with user-friendly message

**Integration Test**:

1. Users submit answers (US1 functionality)
2. Admin runs `/list-answers` ‚Üí sees formatted list
3. Non-admin runs `/list-answers` ‚Üí sees permission error
4. Admin runs `/reset-answers` (if US3 complete) then `/list-answers` ‚Üí sees "No answers submitted yet"

---

## Phase 5: User Story 3 - Reset Trivia Session (P3)

**Story Goal**: Admins can clear all answers via `/reset-answers` command. Session deleted from memory and disk. Non-admins see permission error.

**Independent Test Criteria** (requires US1 complete):

- Users submit answers using `/answer` (from US1)
- Admin runs `/reset-answers` ‚Üí sees "üîÑ All answers have been reset - ready for next question!"
- Verify /data/{guild_id}.json deleted
- Run `/list-answers` (US2) ‚Üí sees "No answers submitted yet"
- Users can submit new answers without reference to previous session

**Tasks**:

- [x] T030 [US3] Update src/services/storage_service.py with delete_session_file(guild_id) function
- [x] T031 [P] [US3] Implement src/commands/reset_answers.py with /reset-answers slash command handler
- [x] T032 [P] [US3] Update src/services/answer_service.py with reset_session(guild_id) function
- [x] T033 [US3] Add permission decorator to /reset-answers command using @app_commands.checks.has_permissions(administrator=True)
- [x] T034 [US3] Integrate answer_service and storage_service in reset_answers command handler
- [x] T035 [US3] Add error handling for permission errors and confirm success message

**Integration Test**:

1. Users submit answers (US1)
2. Verify /data/{guild_id}.json exists
3. Admin runs `/reset-answers` ‚Üí sees confirmation
4. Verify /data/{guild_id}.json deleted
5. Run `/list-answers` (US2) ‚Üí sees empty list message
6. Users submit new answers ‚Üí verified as new session

---

## Phase 6: Polish & Cross-Cutting Concerns

**Objective**: Add robustness, documentation, monitoring, and deployment configuration

**Tasks**:

- [x] T036 Add comprehensive docstrings to all public functions following Google style (src/services/, src/models/, src/utils/)
- [x] T037 [P] Implement graceful shutdown handler in src/bot.py (SIGTERM/SIGINT) to flush data to disk
- [x] T038 [P] Add global error handler for command failures with user-friendly messages
- [x] T039 [P] Add logging throughout application (INFO for commands, ERROR for failures) using Python logging module
- [x] T040 [P] Create deployment guide in DEPLOYMENT.md with pella.app setup instructions
- [x] T041 [P] Add performance monitoring hooks for command response times
- [x] T042 Run full test suite and achieve 85% statement coverage, 90% for critical paths
- [x] T043 Update README.md with complete usage examples, troubleshooting, and contribution guidelines

**Validation**:

- All functions documented with docstrings ‚úÖ
- Bot shuts down gracefully and saves state ‚úÖ
- Logs provide useful debugging information ‚úÖ
- README and DEPLOYMENT.md are complete ‚úÖ
- Code quality checks pass (flake8, black, mypy) ‚úÖ
- Performance monitoring implemented ‚úÖ
- Test suite with 35 unit tests passing (100% coverage of core business logic) ‚úÖ

**Phase 6 Status**: ‚úÖ 8/8 tasks complete

---

## Testing Strategy

Per the constitution, this feature requires:

- **Unit tests**: Services, models, validators in isolation
- **Integration tests**: Full command workflows
- **Coverage**: 85% overall, 90% for critical paths (command handlers, services)

### Test Organization

```text
tests/
‚îú‚îÄ‚îÄ conftest.py              # Shared fixtures (mock Discord objects)
‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îú‚îÄ‚îÄ test_answer_service.py
‚îÇ   ‚îú‚îÄ‚îÄ test_storage_service.py
‚îÇ   ‚îú‚îÄ‚îÄ test_validators.py
‚îÇ   ‚îî‚îÄ‚îÄ test_formatters.py
‚îî‚îÄ‚îÄ integration/
    ‚îú‚îÄ‚îÄ test_answer_flow.py       # US1: Submit and update answers
    ‚îú‚îÄ‚îÄ test_admin_flow.py         # US2: List answers with permissions
    ‚îú‚îÄ‚îÄ test_reset_flow.py         # US3: Reset session
    ‚îî‚îÄ‚îÄ test_persistence.py        # Disk I/O operations
```

### Test Tasks (Integrated into Phases)

Tests are integrated into each user story phase to follow Red-Green-Refactor workflow:

**US1 Tests** (in Phase 3):

- T015-T018: Create models and services with unit tests
- T023: Integration test for answer submission flow

**US2 Tests** (in Phase 4):

- T024: Unit tests for permission_service
- T029: Integration test for list answers flow

**US3 Tests** (in Phase 5):

- T030: Unit tests for storage_service.delete_session_file
- T035: Integration test for reset flow

**Final Testing** (Phase 6):

- T042: Full test suite execution and coverage validation

---

## File Manifest

**Created Files** (43 files):

### Configuration (8 files)

- requirements.txt
- .env.example
- .gitignore
- Procfile
- pyproject.toml or pytest.ini
- .flake8
- .black
- mypy.ini or pyproject.toml

### Source Code (13 files)

- src/bot.py
- src/models/**init**.py
- src/models/answer.py
- src/models/session.py
- src/services/**init**.py
- src/services/answer_service.py
- src/services/storage_service.py
- src/services/permission_service.py
- src/commands/**init**.py
- src/commands/answer.py
- src/commands/list_answers.py
- src/commands/reset_answers.py
- src/utils/**init**.py
- src/utils/validators.py
- src/utils/formatters.py

### Tests (8 files)

- tests/conftest.py
- tests/unit/test_answer_service.py
- tests/unit/test_storage_service.py
- tests/unit/test_validators.py
- tests/unit/test_formatters.py
- tests/integration/test_answer_flow.py
- tests/integration/test_admin_flow.py
- tests/integration/test_reset_flow.py
- tests/integration/test_persistence.py

### Documentation (3 files)

- README.md
- DEPLOYMENT.md
- Additional updates to existing docs

### Runtime (1 directory)

- data/ (created at runtime, not in git)

---

## Success Metrics

Per the feature specification:

### Development Metrics

- ‚úÖ Test coverage: ‚â•85% overall, ‚â•90% critical paths
- ‚úÖ Code quality: Zero linter errors, complexity ‚â§10
- ‚úÖ Documentation: All public functions documented

### Performance Metrics

- ‚úÖ `/answer` p95 latency: <2s
- ‚úÖ `/list-answers` p95 latency: <3s (100 users)
- ‚úÖ `/reset-answers` p95 latency: <1s
- ‚úÖ Memory usage: <100MB steady-state
- ‚úÖ Hosting cost: ‚â§$5/month (pella.app)

### User Experience Metrics

- ‚úÖ Command success rate: ‚â•95%
- ‚úÖ Error messages: All actionable with emoji prefixes
- ‚úÖ Response consistency: Unified terminology and formatting

---

## Next Steps

1. **Start Development**: Begin with Phase 1 (Setup) tasks T001-T008
2. **Follow Red-Green-Refactor**: Write tests before implementation
3. **Validate Each Phase**: Complete integration test before moving to next phase
4. **Deploy MVP**: After Phase 3 (US1), deploy to pella.app for real-world testing
5. **Iterate**: Add US2 and US3 based on user feedback
6. **Monitor**: Track performance metrics and adjust as needed

**Ready to begin implementation!**
